{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95566f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534b82bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Personal Project\\\\Medical-Image-Segmentation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95ec6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    copy_trained_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LiverTumorSegmentation.constants import *\n",
    "from LiverTumorSegmentation.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6feddc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = self.config.training.training_data\n",
    "        create_directories([Path(training.root_dir)])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            copy_trained_model_path=Path(training.copy_trained_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "        return training_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0033472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7240ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "        self.model: Optional[tf.keras.Model] = None\n",
    "\n",
    "    def get_base_model(self):\n",
    "        \"\"\"Load the base model from the updated base model path.\"\"\"\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "\n",
    "    def train_valid_generator(self):\n",
    "        \"\"\"Create train and validation data generators.\"\"\"\n",
    "        # Check if training data directory exists\n",
    "        if not self.config.training_data.exists():\n",
    "            raise FileNotFoundError(\n",
    "                f\"Training data directory not found: {self.config.training_data}\\n\"\n",
    "                f\"Please ensure data ingestion has been completed and the directory exists.\"\n",
    "            )\n",
    "        \n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "        \n",
    "        # Validate that generators have samples\n",
    "        if self.train_generator.samples == 0:\n",
    "            error_msg = (\n",
    "                f\"\\n‚ùå No training images found in {self.config.training_data}\\n\\n\"\n",
    "                f\"ImageDataGenerator expects a CLASSIFICATION directory structure:\\n\"\n",
    "                f\"  {self.config.training_data}/\\n\"\n",
    "                f\"    class1/\\n\"\n",
    "                f\"      image1.jpg\\n\"\n",
    "                f\"      image2.jpg\\n\"\n",
    "                f\"    class2/\\n\"\n",
    "                f\"      image1.jpg\\n\"\n",
    "                f\"      image2.jpg\\n\\n\"\n",
    "                f\"‚ö†Ô∏è  This is a SEGMENTATION project. You have two options:\\n\\n\"\n",
    "                f\"Option 1: Organize your data into class subdirectories\\n\"\n",
    "                f\"  - Create subdirectories for each class\\n\"\n",
    "                f\"  - Place images in their respective class folders\\n\\n\"\n",
    "                f\"Option 2: Use a segmentation data loader\\n\"\n",
    "                f\"  - See artifacts/sample/train_sample.py for an example\\n\"\n",
    "                f\"  - Uses PKLSegmentationDataset for pickle-based segmentation data\\n\\n\"\n",
    "                f\"üí° Run the diagnostic cell above to see what data structure you have.\"\n",
    "            )\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "        if self.valid_generator.samples == 0:\n",
    "            raise ValueError(\n",
    "                f\"No validation images found in {self.config.training_data}\\n\"\n",
    "                f\"Please ensure there are enough images for a 20% validation split.\"\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model) -> None:\n",
    "        \"\"\"Save the trained model to the specified path.\"\"\"\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        model.save(path)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the model using the configured generators.\"\"\"\n",
    "        # Validate generators before training\n",
    "        if not hasattr(self, 'train_generator') or not hasattr(self, 'valid_generator'):\n",
    "            raise ValueError(\"Data generators not initialized. Call train_valid_generator() first.\")\n",
    "        \n",
    "        if self.train_generator.samples == 0:\n",
    "            raise ValueError(\"Cannot train: train_generator has 0 samples.\")\n",
    "        \n",
    "        if self.valid_generator.samples == 0:\n",
    "            raise ValueError(\"Cannot train: valid_generator has 0 samples.\")\n",
    "        \n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "        \n",
    "        # Ensure at least 1 step per epoch\n",
    "        if self.steps_per_epoch == 0:\n",
    "            raise ValueError(\n",
    "                f\"steps_per_epoch is 0. \"\n",
    "                f\"train_generator.samples={self.train_generator.samples}, \"\n",
    "                f\"batch_size={self.train_generator.batch_size}\"\n",
    "            )\n",
    "        \n",
    "        if self.validation_steps == 0:\n",
    "            raise ValueError(\n",
    "                f\"validation_steps is 0. \"\n",
    "                f\"valid_generator.samples={self.valid_generator.samples}, \"\n",
    "                f\"batch_size={self.valid_generator.batch_size}\"\n",
    "            )\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )\n",
    "\n",
    "    def copy_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Copy the trained model file to the `copy_trained_model_path`\n",
    "        directory defined in the configuration.\n",
    "        \"\"\"\n",
    "        src = Path(self.config.trained_model_path)\n",
    "        dst_dir = Path(self.config.copy_trained_model_path)\n",
    "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dst = dst_dir / src.name\n",
    "        shutil.copy2(src, dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7f0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-20 23:07:20,552: INFO: common: yaml file: configs\\config.yaml loaded successfully]\n",
      "[2026-01-20 23:07:20,560: INFO: common: yaml file: configs\\params.yaml loaded successfully]\n",
      "[2026-01-20 23:07:20,562: INFO: common: created directory at: artifacts]\n",
      "[2026-01-20 23:07:20,565: INFO: common: created directory at: artifacts\\training]\n",
      "Checking data directory: artifacts\\data_ingestion\\data\n",
      "Exists: True\n",
      "\n",
      "Contents of artifacts\\data_ingestion\\data:\n",
      "  üìÅ GroundTruth/ (87 items)\n",
      "  üìÅ Predictions/ (33 items)\n",
      "\n",
      "Found 0 image files\n",
      "Found 2958 pickle files\n",
      "\n",
      "‚ö†Ô∏è  Pickle files detected - this suggests segmentation data.\n",
      "   You may need to use a segmentation data loader instead of ImageDataGenerator.\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check what data structure exists\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "config = ConfigurationManager()\n",
    "training_config = config.get_training_config()\n",
    "data_path = training_config.training_data\n",
    "\n",
    "print(f\"Checking data directory: {data_path}\")\n",
    "print(f\"Exists: {data_path.exists()}\")\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"\\nContents of {data_path}:\")\n",
    "    for item in sorted(data_path.iterdir()):\n",
    "        if item.is_dir():\n",
    "            file_count = len(list(item.glob(\"*\")))\n",
    "            print(f\"  üìÅ {item.name}/ ({file_count} items)\")\n",
    "        else:\n",
    "            print(f\"  üìÑ {item.name}\")\n",
    "    \n",
    "    # Check for common image formats\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.nii', '.nii.gz'}\n",
    "    all_files = list(data_path.rglob(\"*\"))\n",
    "    image_files = [f for f in all_files if f.suffix.lower() in image_extensions or f.suffixes[-2:] == ['.nii', '.gz']]\n",
    "    pickle_files = list(data_path.rglob(\"*.pkl*\"))\n",
    "    \n",
    "    print(f\"\\nFound {len(image_files)} image files\")\n",
    "    print(f\"Found {len(pickle_files)} pickle files\")\n",
    "    \n",
    "    if len(pickle_files) > 0:\n",
    "        print(\"\\n‚ö†Ô∏è  Pickle files detected - this suggests segmentation data.\")\n",
    "        print(\"   You may need to use a segmentation data loader instead of ImageDataGenerator.\")\n",
    "    elif len(image_files) == 0:\n",
    "        print(\"\\n‚ö†Ô∏è  No image files found. Check your data ingestion process.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Directory does not exist. Run data ingestion first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "288d1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-20 23:07:21,163: INFO: common: yaml file: configs\\config.yaml loaded successfully]\n",
      "[2026-01-20 23:07:21,167: INFO: common: yaml file: configs\\params.yaml loaded successfully]\n",
      "[2026-01-20 23:07:21,169: INFO: common: created directory at: artifacts]\n",
      "[2026-01-20 23:07:21,171: INFO: common: created directory at: artifacts\\training]\n",
      "[2026-01-20 23:07:21,420: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n‚ùå No training images found in artifacts\\data_ingestion\\data\n\nImageDataGenerator expects a CLASSIFICATION directory structure:\n  artifacts\\data_ingestion\\data/\n    class1/\n      image1.jpg\n      image2.jpg\n    class2/\n      image1.jpg\n      image2.jpg\n\n‚ö†Ô∏è  This is a SEGMENTATION project. You have two options:\n\nOption 1: Organize your data into class subdirectories\n  - Create subdirectories for each class\n  - Place images in their respective class folders\n\nOption 2: Use a segmentation data loader\n  - See artifacts/sample/train_sample.py for an example\n  - Uses PKLSegmentationDataset for pickle-based segmentation data\n\nüí° Run the diagnostic cell above to see what data structure you have.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     training.copy_model()\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m training = Training(config=training_config)\n\u001b[32m      5\u001b[39m training.get_base_model()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_valid_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m training.train()\n\u001b[32m      8\u001b[39m training.copy_model()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mTraining.train_valid_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_generator.samples == \u001b[32m0\u001b[39m:\n\u001b[32m     65\u001b[39m     error_msg = (\n\u001b[32m     66\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚ùå No training images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.training_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     67\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImageDataGenerator expects a CLASSIFICATION directory structure:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müí° Run the diagnostic cell above to see what data structure you have.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.valid_generator.samples == \u001b[32m0\u001b[39m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo validation images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.training_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease ensure there are enough images for a 20% validation split.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \n‚ùå No training images found in artifacts\\data_ingestion\\data\n\nImageDataGenerator expects a CLASSIFICATION directory structure:\n  artifacts\\data_ingestion\\data/\n    class1/\n      image1.jpg\n      image2.jpg\n    class2/\n      image1.jpg\n      image2.jpg\n\n‚ö†Ô∏è  This is a SEGMENTATION project. You have two options:\n\nOption 1: Organize your data into class subdirectories\n  - Create subdirectories for each class\n  - Place images in their respective class folders\n\nOption 2: Use a segmentation data loader\n  - See artifacts/sample/train_sample.py for an example\n  - Uses PKLSegmentationDataset for pickle-based segmentation data\n\nüí° Run the diagnostic cell above to see what data structure you have."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train()\n",
    "    training.copy_model()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb885b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d99eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
